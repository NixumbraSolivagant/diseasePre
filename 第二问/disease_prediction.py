# -*- coding: utf-8 -*-
"""
ç¬¬äºŒé—®ï¼šä¸åŒç–¾ç—…é¢„æµ‹æ¨¡å‹çš„æ„å»º - æè‡´GPUåŠ é€Ÿç‰ˆæœ¬
åˆ†è€Œæ²»ä¹‹çš„é›†æˆå­¦ä¹ æ–¹æ¡ˆï¼š
1. ä¸“ç§‘åŒ»ç”Ÿæ¨¡å‹ï¼ˆå•ç–¾ç—…ä¸“å®¶ï¼‰
2. æ€»åˆ†æå¸ˆå…ƒæ¨¡å‹ï¼ˆç»“æœèåˆï¼‰
ä½¿ç”¨CatBoostå®ç°æè‡´GPUåŠ é€Ÿ
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.preprocessing import StandardScaler, LabelEncoder
import catboost as cb
import shap
import warnings
import joblib
import pickle
from tqdm import tqdm
import time
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.size'] = 12

# æè‡´GPUåŠ é€Ÿè®¾ç½®
try:
    import cupy as cp
    USE_GPU = True
    print("ğŸš€ æè‡´GPUåŠ é€Ÿå·²å¯ç”¨")
    
    # è®¾ç½®CuPyå†…å­˜æ± ä»¥ä¼˜åŒ–GPUå†…å­˜ä½¿ç”¨
    pool = cp.get_default_memory_pool()
    pool.set_limit(size=1024**3)  # 1GB GPUå†…å­˜é™åˆ¶
    
    # è®¾ç½®GPUè®¾å¤‡
    if cp.cuda.runtime.getDeviceCount() > 0:
        print(f"ğŸ¯ æ£€æµ‹åˆ° {cp.cuda.runtime.getDeviceCount()} ä¸ªGPUè®¾å¤‡")
        for i in range(cp.cuda.runtime.getDeviceCount()):
            props = cp.cuda.runtime.getDeviceProperties(i)
            print(f"   GPU {i}: {props['name'].decode()}")
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ°GPUè®¾å¤‡ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        USE_GPU = False
        
except ImportError:
    USE_GPU = False
    print("âš ï¸  CuPyæœªå®‰è£…ï¼Œä½¿ç”¨CPUæ¨¡å¼")

class DiseasePredictor:
    """ç–¾ç—…é¢„æµ‹å™¨ - æè‡´GPUåŠ é€Ÿç‰ˆæœ¬"""
    
    def __init__(self):
        self.specialists = {}  # ä¸“ç§‘åŒ»ç”Ÿæ¨¡å‹
        self.meta_model = None  # æ€»åˆ†æå¸ˆå…ƒæ¨¡å‹
        self.scalers = {}  # æ ‡å‡†åŒ–å™¨
        self.label_encoders = {}  # æ ‡ç­¾ç¼–ç å™¨
        self.feature_importance = {}  # ç‰¹å¾é‡è¦æ€§
        self.shap_values = {}  # SHAPå€¼
        self.gpu_data = {}  # GPUæ•°æ®ç¼“å­˜
        
        # åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
        self.model_dir = "models"
        os.makedirs(self.model_dir, exist_ok=True)
        os.makedirs(f"{self.model_dir}/specialists", exist_ok=True)
        os.makedirs(f"{self.model_dir}/meta", exist_ok=True)
        os.makedirs(f"{self.model_dir}/preprocessors", exist_ok=True)
        
        # GPUåŠ é€Ÿé…ç½®
        self.gpu_config = {
            'task_type': 'GPU' if USE_GPU else 'CPU',
            'devices': '0' if USE_GPU else None,
            'gpu_ram_part': 0.8,  # ä½¿ç”¨80%çš„GPUå†…å­˜
            'thread_count': -1,  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
            'verbose': False
        }
        
        print(f"ğŸ›ï¸  GPUé…ç½®: {self.gpu_config}")
        
    def _to_gpu(self, data):
        """å°†æ•°æ®è½¬ç§»åˆ°GPU"""
        if USE_GPU and isinstance(data, (np.ndarray, pd.DataFrame)):
            if isinstance(data, pd.DataFrame):
                return cp.asarray(data.values)
            return cp.asarray(data)
        return data
    
    def _to_cpu(self, data):
        """å°†æ•°æ®ä»GPUè½¬ç§»åˆ°CPU"""
        if USE_GPU and isinstance(data, cp.ndarray):
            return cp.asnumpy(data)
        return data
        
    def save_models(self):
        """ä¿å­˜æ‰€æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹"""
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜æ¨¡å‹...")
        
        # ä¿å­˜ä¸“ç§‘åŒ»ç”Ÿæ¨¡å‹
        for disease in ['stroke', 'heart', 'cirrhosis']:
            if disease in self.specialists:
                best_model = self.specialists[disease]['best_model']
                best_model_name = self.specialists[disease]['best_model_name']
                
                model_path = f"{self.model_dir}/specialists/{disease}_{best_model_name}.cbm"
                best_model.save_model(model_path)
                print(f"   âœ… ä¿å­˜ {disease} æœ€ä½³æ¨¡å‹: {model_path}")
        
        # ä¿å­˜å…ƒæ¨¡å‹
        if self.meta_model is not None:
            meta_model_path = f"{self.model_dir}/meta/meta_model.cbm"
            self.meta_model.save_model(meta_model_path)
            print(f"   âœ… ä¿å­˜å…ƒæ¨¡å‹: {meta_model_path}")
        
        # ä¿å­˜é¢„å¤„ç†å™¨
        preprocessors = {
            'scalers': self.scalers,
            'label_encoders': self.label_encoders
        }
        preprocessors_path = f"{self.model_dir}/preprocessors/preprocessors.pkl"
        with open(preprocessors_path, 'wb') as f:
            pickle.dump(preprocessors, f)
        print(f"   âœ… ä¿å­˜é¢„å¤„ç†å™¨: {preprocessors_path}")
        
        # ä¿å­˜æ¨¡å‹ä¿¡æ¯
        model_info = {
            'specialists': {disease: {
                'best_model_name': self.specialists[disease]['best_model_name'],
                'model_path': f"{self.model_dir}/specialists/{disease}_{self.specialists[disease]['best_model_name']}.cbm"
            } for disease in self.specialists.keys()},
            'meta_model_path': f"{self.model_dir}/meta/meta_model.cbm",
            'preprocessors_path': preprocessors_path,
            'gpu_config': self.gpu_config
        }
        
        info_path = f"{self.model_dir}/model_info.json"
        import json
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, indent=2, ensure_ascii=False)
        print(f"   âœ… ä¿å­˜æ¨¡å‹ä¿¡æ¯: {info_path}")
        
        print("ğŸ‰ æ¨¡å‹ä¿å­˜å®Œæˆï¼")
        
    def load_models(self):
        """åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹"""
        print("ğŸ“‚ æ­£åœ¨åŠ è½½æ¨¡å‹...")
        
        # åŠ è½½æ¨¡å‹ä¿¡æ¯
        info_path = f"{self.model_dir}/model_info.json"
        if os.path.exists(info_path):
            import json
            with open(info_path, 'r', encoding='utf-8') as f:
                model_info = json.load(f)
            
            # åŠ è½½é¢„å¤„ç†å™¨
            preprocessors_path = model_info['preprocessors_path']
            with open(preprocessors_path, 'rb') as f:
                preprocessors = pickle.load(f)
            self.scalers = preprocessors['scalers']
            self.label_encoders = preprocessors['label_encoders']
            
            # åŠ è½½ä¸“ç§‘åŒ»ç”Ÿæ¨¡å‹
            for disease, info in model_info['specialists'].items():
                model_path = info['model_path']
                model = cb.CatBoostClassifier()
                model.load_model(model_path)
                
                self.specialists[disease] = {
                    'best_model': model,
                    'best_model_name': info['best_model_name']
                }
            
            # åŠ è½½å…ƒæ¨¡å‹
            meta_model_path = model_info['meta_model_path']
            self.meta_model = cb.CatBoostClassifier()
            self.meta_model.load_model(meta_model_path)
            
            print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")
            return True
        else:
            print("âš ï¸  æœªæ‰¾åˆ°å·²ä¿å­˜çš„æ¨¡å‹ï¼Œéœ€è¦é‡æ–°è®­ç»ƒ")
            return False
        
    def load_and_preprocess_data(self):
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ® - GPUåŠ é€Ÿç‰ˆæœ¬"""
        print("ğŸ”„ æ­£åœ¨åŠ è½½å’Œé¢„å¤„ç†æ•°æ®...")
        start_time = time.time()
        
        # åŠ è½½æ•°æ®
        data_dir = "./é™„ä»¶"
        self.stroke_data = pd.read_csv(f"{data_dir}/stroke.csv", encoding='utf-8-sig')
        self.heart_data = pd.read_csv(f"{data_dir}/heart.csv", encoding='utf-8-sig')
        self.cirrhosis_data = pd.read_csv(f"{data_dir}/cirrhosis.csv", encoding='utf-8-sig')
        
        print(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ: ä¸­é£({len(self.stroke_data)}è¡Œ), å¿ƒè„ç—…({len(self.heart_data)}è¡Œ), è‚ç¡¬åŒ–({len(self.cirrhosis_data)}è¡Œ)")
        
        # GPUåŠ é€Ÿæ•°æ®é¢„å¤„ç†
        self._preprocess_stroke_data()
        self._preprocess_heart_data()
        self._preprocess_cirrhosis_data()
        
        elapsed_time = time.time() - start_time
        print(f"âš¡ æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
        
    def _preprocess_stroke_data(self):
        """é¢„å¤„ç†ä¸­é£æ•°æ® - GPUåŠ é€Ÿ"""
        df = self.stroke_data.copy()
        
        # å¤„ç†ç¼ºå¤±å€¼
        df = df.fillna(df.mode().iloc[0])
        
        # ç¼–ç åˆ†ç±»å˜é‡
        categorical_cols = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']
        for col in categorical_cols:
            if col in df.columns:
                le = LabelEncoder()
                df[col] = le.fit_transform(df[col].astype(str))
                self.label_encoders[f'stroke_{col}'] = le
        
        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
        X = df.drop(['id', 'stroke'], axis=1, errors='ignore')
        y = df['stroke']
        
        # GPUåŠ é€Ÿæ ‡å‡†åŒ–
        if USE_GPU:
            X_gpu = self._to_gpu(X)
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(self._to_cpu(X_gpu))
            X_scaled = self._to_gpu(X_scaled)
        else:
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
        
        self.scalers['stroke'] = scaler
        
        self.stroke_X = pd.DataFrame(self._to_cpu(X_scaled), columns=X.columns)
        self.stroke_y = y
        
        # ç¼“å­˜GPUæ•°æ®
        if USE_GPU:
            self.gpu_data['stroke_X'] = self._to_gpu(self.stroke_X)
            self.gpu_data['stroke_y'] = self._to_gpu(self.stroke_y)
        
    def _preprocess_heart_data(self):
        """é¢„å¤„ç†å¿ƒè„ç—…æ•°æ® - GPUåŠ é€Ÿ"""
        df = self.heart_data.copy()
        
        # å¤„ç†ç¼ºå¤±å€¼
        df = df.fillna(df.mode().iloc[0])
        
        # ç¼–ç åˆ†ç±»å˜é‡
        categorical_cols = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']
        for col in categorical_cols:
            if col in df.columns:
                le = LabelEncoder()
                df[col] = le.fit_transform(df[col].astype(str))
                self.label_encoders[f'heart_{col}'] = le
        
        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
        X = df.drop(['HeartDisease'], axis=1, errors='ignore')
        y = df['HeartDisease']
        
        # GPUåŠ é€Ÿæ ‡å‡†åŒ–
        if USE_GPU:
            X_gpu = self._to_gpu(X)
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(self._to_cpu(X_gpu))
            X_scaled = self._to_gpu(X_scaled)
        else:
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
        
        self.scalers['heart'] = scaler
        
        self.heart_X = pd.DataFrame(self._to_cpu(X_scaled), columns=X.columns)
        self.heart_y = y
        
        # ç¼“å­˜GPUæ•°æ®
        if USE_GPU:
            self.gpu_data['heart_X'] = self._to_gpu(self.heart_X)
            self.gpu_data['heart_y'] = self._to_gpu(self.heart_y)
        
    def _preprocess_cirrhosis_data(self):
        """é¢„å¤„ç†è‚ç¡¬åŒ–æ•°æ® - GPUåŠ é€Ÿ"""
        df = self.cirrhosis_data.copy()
        
        # å¤„ç†ç¼ºå¤±å€¼
        df = df.fillna(df.mode().iloc[0])
        
        # ç¼–ç åˆ†ç±»å˜é‡
        categorical_cols = ['Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema', 'Status', 'Drug']
        for col in categorical_cols:
            if col in df.columns:
                le = LabelEncoder()
                df[col] = le.fit_transform(df[col].astype(str))
                self.label_encoders[f'cirrhosis_{col}'] = le
        
        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
        X = df.drop(['ID', 'Stage'], axis=1, errors='ignore')
        y = (df['Stage'] > 1).astype(int)  # å°†Stage>1è§†ä¸ºæ‚£ç—…
        
        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯æ•°å€¼å‹
        for col in X.columns:
            if X[col].dtype == 'object':
                try:
                    X[col] = pd.to_numeric(X[col], errors='coerce')
                    X[col] = X[col].fillna(0)
                except:
                    le = LabelEncoder()
                    X[col] = le.fit_transform(X[col].astype(str))
                    self.label_encoders[f'cirrhosis_{col}'] = le
        
        # GPUåŠ é€Ÿæ ‡å‡†åŒ–
        if USE_GPU:
            X_gpu = self._to_gpu(X)
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(self._to_cpu(X_gpu))
            X_scaled = self._to_gpu(X_scaled)
        else:
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
        
        self.scalers['cirrhosis'] = scaler
        
        self.cirrhosis_X = pd.DataFrame(self._to_cpu(X_scaled), columns=X.columns)
        self.cirrhosis_y = y
        
        # ç¼“å­˜GPUæ•°æ®
        if USE_GPU:
            self.gpu_data['cirrhosis_X'] = self._to_gpu(self.cirrhosis_X)
            self.gpu_data['cirrhosis_y'] = self._to_gpu(self.cirrhosis_y)
        
    def train_specialists(self):
        """è®­ç»ƒä¸“ç§‘åŒ»ç”Ÿæ¨¡å‹ - æè‡´GPUåŠ é€Ÿç‰ˆæœ¬"""
        print("ğŸ¥ æ­£åœ¨è®­ç»ƒä¸“ç§‘åŒ»ç”Ÿæ¨¡å‹...")
        start_time = time.time()
        
        # ä¸­é£ä¸“å®¶
        print("ğŸ§  è®­ç»ƒä¸­é£ä¸“å®¶...")
        self._train_specialist('stroke', self.stroke_X, self.stroke_y)
        
        # å¿ƒè„ç—…ä¸“å®¶
        print("â¤ï¸  è®­ç»ƒå¿ƒè„ç—…ä¸“å®¶...")
        self._train_specialist('heart', self.heart_X, self.heart_y)
        
        # è‚ç¡¬åŒ–ä¸“å®¶
        print("ğŸ« è®­ç»ƒè‚ç¡¬åŒ–ä¸“å®¶...")
        self._train_specialist('cirrhosis', self.cirrhosis_X, self.cirrhosis_y)
        
        elapsed_time = time.time() - start_time
        print(f"âš¡ ä¸“ç§‘åŒ»ç”Ÿæ¨¡å‹è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
        
    def _train_specialist(self, disease, X, y):
        """è®­ç»ƒå•ä¸ªä¸“ç§‘åŒ»ç”Ÿæ¨¡å‹ - æè‡´GPUåŠ é€Ÿ"""
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # æè‡´GPUåŠ é€Ÿçš„CatBoosté…ç½®
        catboost_config = {
            **self.gpu_config,
            'iterations': 1000,
            'learning_rate': 0.1,
            'depth': 8,
            'l2_leaf_reg': 3,
            'bootstrap_type': 'Bernoulli',
            'subsample': 0.8,
            'random_seed': 42,
            'eval_metric': 'AUC',
            'early_stopping_rounds': 50,
            'verbose': 100
        }
        
        print(f"   ğŸš€ ä½¿ç”¨æè‡´GPUåŠ é€Ÿé…ç½®è®­ç»ƒ {disease} æ¨¡å‹...")
        
        # è®­ç»ƒCatBoostæ¨¡å‹
        model = cb.CatBoostClassifier(**catboost_config)
        
        # CatBoostéœ€è¦CPUæ ¼å¼çš„æ•°æ®ï¼Œä½†ä½¿ç”¨GPUè®­ç»ƒ
        # ç¡®ä¿æ•°æ®æ˜¯CPUæ ¼å¼çš„numpyæ•°ç»„æˆ–pandas DataFrame
        if isinstance(X_train, pd.DataFrame):
            X_train_cpu = X_train
            X_test_cpu = X_test
            y_train_cpu = y_train
            y_test_cpu = y_test
        else:
            # å¦‚æœæ˜¯GPUæ•°ç»„ï¼Œè½¬æ¢ä¸ºCPUæ ¼å¼
            X_train_cpu = self._to_cpu(X_train)
            X_test_cpu = self._to_cpu(X_test)
            y_train_cpu = self._to_cpu(y_train)
            y_test_cpu = self._to_cpu(y_test)
            
            # è½¬æ¢ä¸ºDataFrameä»¥ä¿æŒåˆ—å
            if isinstance(X_train_cpu, np.ndarray):
                X_train_cpu = pd.DataFrame(X_train_cpu, columns=X.columns)
                X_test_cpu = pd.DataFrame(X_test_cpu, columns=X.columns)
        
        # è®­ç»ƒæ¨¡å‹ï¼ˆCatBoostå†…éƒ¨ä¼šä½¿ç”¨GPUï¼‰
        model.fit(
            X_train_cpu, y_train_cpu,
            eval_set=(X_test_cpu, y_test_cpu),
            plot=False
        )
        
        # é¢„æµ‹
        y_pred = model.predict(X_test_cpu)
        y_pred_proba = model.predict_proba(X_test_cpu)[:, 1]
        
        # è¯„ä¼°æŒ‡æ ‡
        accuracy = accuracy_score(y_test_cpu, y_pred)
        precision = precision_score(y_test_cpu, y_pred, zero_division=0)
        recall = recall_score(y_test_cpu, y_pred, zero_division=0)
        f1 = f1_score(y_test_cpu, y_pred, zero_division=0)
        auc = roc_auc_score(y_test_cpu, y_pred_proba)
        
        results = {
            'catboost': {
                'model': model,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'auc': auc,
                'y_pred_proba': y_pred_proba
            }
        }
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹å’Œç»“æœ
        self.specialists[disease] = {
            'best_model': model,
            'best_model_name': 'catboost',
            'results': results,
            'X_test': X_test_cpu,
            'y_test': y_test_cpu
        }
        
        print(f"   âœ… {disease} æ¨¡å‹è®­ç»ƒå®Œæˆ (AUC: {auc:.4f})")
        
        # è®¡ç®—ç‰¹å¾é‡è¦æ€§
        self.feature_importance[disease] = dict(zip(
            X.columns, 
            model.get_feature_importance()
        ))
        
        # è®¡ç®—SHAPå€¼
        explainer = shap.TreeExplainer(model)
        self.shap_values[disease] = explainer.shap_values(X_test_cpu)
        
    def create_meta_features(self):
        """åˆ›å»ºå…ƒç‰¹å¾ - GPUåŠ é€Ÿç‰ˆæœ¬"""
        print("ğŸ”— æ­£åœ¨åˆ›å»ºå…ƒç‰¹å¾...")
        start_time = time.time()
        
        meta_features = []
        meta_labels = []
        
        # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ›å»ºå…ƒç‰¹å¾
        for disease in ['stroke', 'heart', 'cirrhosis']:
            X = getattr(self, f'{disease}_X')
            y = getattr(self, f'{disease}_y')
            
            # è·å–ä¸“ç§‘åŒ»ç”Ÿçš„é¢„æµ‹æ¦‚ç‡
            specialist = self.specialists[disease]['best_model']
            probabilities = specialist.predict_proba(X)[:, 1]
            
            # åˆ›å»ºå…ƒç‰¹å¾ï¼šä¸“ç§‘åŒ»ç”Ÿé¢„æµ‹ + åŸºæœ¬ä¿¡æ¯
            meta_feature = {
                f'{disease}_prob': probabilities,
                'age': X['Age'] if 'Age' in X.columns else X['age'] if 'age' in X.columns else 0,
                'gender': X['Sex'] if 'Sex' in X.columns else X['gender'] if 'gender' in X.columns else 0
            }
            
            meta_features.append(pd.DataFrame(meta_feature))
            meta_labels.append(y)
        
        # åˆå¹¶æ‰€æœ‰å…ƒç‰¹å¾
        self.meta_X = pd.concat(meta_features, ignore_index=True)
        self.meta_y = pd.concat(meta_labels, ignore_index=True)
        
        # GPUç¼“å­˜
        if USE_GPU:
            self.gpu_data['meta_X'] = self._to_gpu(self.meta_X)
            self.gpu_data['meta_y'] = self._to_gpu(self.meta_y)
        
        elapsed_time = time.time() - start_time
        print(f"âš¡ å…ƒç‰¹å¾åˆ›å»ºå®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
        
    def train_meta_model(self):
        """è®­ç»ƒæ€»åˆ†æå¸ˆå…ƒæ¨¡å‹ - æè‡´GPUåŠ é€Ÿ"""
        print("ğŸ§  æ­£åœ¨è®­ç»ƒæ€»åˆ†æå¸ˆå…ƒæ¨¡å‹...")
        start_time = time.time()
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            self.meta_X, self.meta_y, test_size=0.2, random_state=42, stratify=self.meta_y
        )
        
        # æè‡´GPUåŠ é€Ÿçš„å…ƒæ¨¡å‹é…ç½®
        meta_config = {
            **self.gpu_config,
            'iterations': 500,
            'learning_rate': 0.05,
            'depth': 6,
            'l2_leaf_reg': 5,
            'bootstrap_type': 'Bernoulli',
            'subsample': 0.9,
            'random_seed': 42,
            'eval_metric': 'AUC',
            'early_stopping_rounds': 30,
            'verbose': 100
        }
        
        # ä½¿ç”¨CatBoostä½œä¸ºå…ƒæ¨¡å‹
        self.meta_model = cb.CatBoostClassifier(**meta_config)
        
        # ç¡®ä¿æ•°æ®æ˜¯CPUæ ¼å¼
        if isinstance(X_train, pd.DataFrame):
            X_train_cpu = X_train
            X_test_cpu = X_test
            y_train_cpu = y_train
            y_test_cpu = y_test
        else:
            # å¦‚æœæ˜¯GPUæ•°ç»„ï¼Œè½¬æ¢ä¸ºCPUæ ¼å¼
            X_train_cpu = self._to_cpu(X_train)
            X_test_cpu = self._to_cpu(X_test)
            y_train_cpu = self._to_cpu(y_train)
            y_test_cpu = self._to_cpu(y_test)
            
            # è½¬æ¢ä¸ºDataFrameä»¥ä¿æŒåˆ—å
            if isinstance(X_train_cpu, np.ndarray):
                X_train_cpu = pd.DataFrame(X_train_cpu, columns=self.meta_X.columns)
                X_test_cpu = pd.DataFrame(X_test_cpu, columns=self.meta_X.columns)
        
        # è®­ç»ƒæ¨¡å‹ï¼ˆCatBoostå†…éƒ¨ä¼šä½¿ç”¨GPUï¼‰
        self.meta_model.fit(
            X_train_cpu, y_train_cpu,
            eval_set=(X_test_cpu, y_test_cpu),
            plot=False
        )
        
        # è¯„ä¼°å…ƒæ¨¡å‹
        y_pred = self.meta_model.predict(X_test_cpu)
        y_pred_proba = self.meta_model.predict_proba(X_test_cpu)[:, 1]
        
        self.meta_results = {
            'accuracy': accuracy_score(y_test_cpu, y_pred),
            'precision': precision_score(y_test_cpu, y_pred, zero_division=0),
            'recall': recall_score(y_test_cpu, y_pred, zero_division=0),
            'f1': f1_score(y_test_cpu, y_pred, zero_division=0),
            'auc': roc_auc_score(y_test_cpu, y_pred_proba)
        }
        
        elapsed_time = time.time() - start_time
        print(f"âš¡ å…ƒæ¨¡å‹è®­ç»ƒå®Œæˆ (AUC: {self.meta_results['auc']:.4f})ï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
        
    def sensitivity_analysis(self):
        """çµæ•åº¦åˆ†æ - GPUåŠ é€Ÿç‰ˆæœ¬"""
        print("ğŸ” æ­£åœ¨è¿›è¡Œçµæ•åº¦åˆ†æ...")
        start_time = time.time()
        
        sensitivity_results = {}
        
        for disease in ['stroke', 'heart', 'cirrhosis']:
            print(f"ğŸ”¬ åˆ†æ {disease} æ¨¡å‹çµæ•åº¦...")
            
            # ç¬¬ä¸€å±‚ï¼šç‰¹å¾æ‰°åŠ¨åˆ†æ
            feature_sensitivity = self._feature_perturbation_analysis(disease)
            
            # ç¬¬äºŒå±‚ï¼šæ¨¡å‹ç¨³å®šæ€§æ£€éªŒ
            model_stability = self._bootstrap_stability_analysis(disease)
            
            sensitivity_results[disease] = {
                'feature_sensitivity': feature_sensitivity,
                'model_stability': model_stability
            }
        
        self.sensitivity_results = sensitivity_results
        
        elapsed_time = time.time() - start_time
        print(f"âš¡ çµæ•åº¦åˆ†æå®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
        
    def _feature_perturbation_analysis(self, disease):
        """ç‰¹å¾æ‰°åŠ¨åˆ†æ - GPUåŠ é€Ÿ"""
        X = getattr(self, f'{disease}_X')
        y = getattr(self, f'{disease}_y')
        model = self.specialists[disease]['best_model']
        
        # é€‰æ‹©æ ¸å¿ƒç‰¹å¾
        if disease == 'stroke':
            core_features = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi']
        elif disease == 'heart':
            core_features = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']
        else:  # cirrhosis
            core_features = ['Age', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper']
        
        # è¿‡æ»¤å­˜åœ¨çš„ç‰¹å¾
        core_features = [f for f in core_features if f in X.columns]
        
        sensitivity = {}
        perturbations = [-0.2, -0.1, 0, 0.1, 0.2]  # Â±20%æ‰°åŠ¨
        
        for feature in tqdm(core_features, desc=f"ğŸ” Feature perturbation analysis for {disease}"):
            original_values = X[feature].copy()
            prob_changes = []
            
            for pert in perturbations:
                # åº”ç”¨æ‰°åŠ¨
                X_perturbed = X.copy()
                X_perturbed[feature] = original_values * (1 + pert)
                
                # GPUåŠ é€Ÿé¢„æµ‹
                if USE_GPU:
                    X_gpu = self._to_gpu(X)
                    X_perturbed_gpu = self._to_gpu(X_perturbed)
                    
                    original_probs = model.predict_proba(self._to_cpu(X_gpu))[:, 1]
                    perturbed_probs = model.predict_proba(self._to_cpu(X_perturbed_gpu))[:, 1]
                else:
                    original_probs = model.predict_proba(X)[:, 1]
                    perturbed_probs = model.predict_proba(X_perturbed)[:, 1]
                
                # è®¡ç®—å˜åŒ–ç‡
                change_rate = np.mean(np.abs(perturbed_probs - original_probs) / (original_probs + 1e-8))
                prob_changes.append(change_rate)
            
            sensitivity[feature] = dict(zip(perturbations, prob_changes))
        
        return sensitivity
        
    def _bootstrap_stability_analysis(self, disease):
        """Bootstrapç¨³å®šæ€§åˆ†æ - GPUåŠ é€Ÿ"""
        X = getattr(self, f'{disease}_X')
        y = getattr(self, f'{disease}_y')
        
        n_bootstrap = 50  # å‡å°‘åˆ°50æ¬¡ä»¥åŠ å¿«é€Ÿåº¦
        prob_std = []
        
        for _ in tqdm(range(n_bootstrap), desc=f"ğŸ”„ Bootstrap stability analysis for {disease}"):
            # Bootstrapé‡‡æ ·
            indices = np.random.choice(len(X), size=len(X), replace=True)
            X_boot = X.iloc[indices]
            y_boot = y.iloc[indices]
            
            # GPUåŠ é€Ÿè®­ç»ƒ
            config = {
                **self.gpu_config,
                'iterations': 100,
                'learning_rate': 0.1,
                'depth': 6,
                'random_seed': 42,
                'verbose': False
            }
            
            model = cb.CatBoostClassifier(**config)
            
            # ç¡®ä¿æ•°æ®æ˜¯CPUæ ¼å¼
            if isinstance(X_boot, pd.DataFrame):
                X_boot_cpu = X_boot
                y_boot_cpu = y_boot
            else:
                # å¦‚æœæ˜¯GPUæ•°ç»„ï¼Œè½¬æ¢ä¸ºCPUæ ¼å¼
                X_boot_cpu = self._to_cpu(X_boot)
                y_boot_cpu = self._to_cpu(y_boot)
                
                # è½¬æ¢ä¸ºDataFrameä»¥ä¿æŒåˆ—å
                if isinstance(X_boot_cpu, np.ndarray):
                    X_boot_cpu = pd.DataFrame(X_boot_cpu, columns=X.columns)
            
            # è®­ç»ƒæ¨¡å‹ï¼ˆCatBoostå†…éƒ¨ä¼šä½¿ç”¨GPUï¼‰
            model.fit(X_boot_cpu, y_boot_cpu, verbose=False)
            
            # é¢„æµ‹æµ‹è¯•é›†
            X_test = self.specialists[disease]['X_test']
            
            # ç¡®ä¿æµ‹è¯•æ•°æ®ä¹Ÿæ˜¯CPUæ ¼å¼
            if isinstance(X_test, pd.DataFrame):
                X_test_cpu = X_test
            else:
                X_test_cpu = self._to_cpu(X_test)
                if isinstance(X_test_cpu, np.ndarray):
                    X_test_cpu = pd.DataFrame(X_test_cpu, columns=X.columns)
            
            probs = model.predict_proba(X_test_cpu)[:, 1]
            prob_std.append(probs)
        
        # è®¡ç®—æ¦‚ç‡æ ‡å‡†å·®
        prob_std = np.std(prob_std, axis=0)
        return np.mean(prob_std)
        
    def generate_reports(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("ğŸ“Š æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs("output/csv/ç¬¬äºŒé—®", exist_ok=True)
        os.makedirs("output/plt/ç¬¬äºŒé—®", exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹æ€§èƒ½æŠ¥å‘Š
        self._save_performance_report()
        
        # ä¿å­˜ç‰¹å¾é‡è¦æ€§
        self._save_feature_importance()
        
        # ç”Ÿæˆå¯è§†åŒ–
        self._generate_visualizations()
        
        print("âœ… åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        
    def _save_performance_report(self):
        """ä¿å­˜æ¨¡å‹æ€§èƒ½æŠ¥å‘Š"""
        report_data = []
        
        # ä¸“ç§‘åŒ»ç”Ÿæ¨¡å‹æ€§èƒ½
        for disease in ['stroke', 'heart', 'cirrhosis']:
            results = self.specialists[disease]['results']
            best_model = self.specialists[disease]['best_model_name']
            
            for model_name, result in results.items():
                report_data.append({
                    'Disease': disease,
                    'Model': model_name,
                    'Best_Model': model_name == best_model,
                    'Accuracy': result['accuracy'],
                    'Precision': result['precision'],
                    'Recall': result['recall'],
                    'F1_Score': result['f1'],
                    'AUC': result['auc']
                })
        
        # å…ƒæ¨¡å‹æ€§èƒ½
        report_data.append({
            'Disease': 'Meta_Model',
            'Model': 'CatBoost',
            'Best_Model': True,
            'Accuracy': self.meta_results['accuracy'],
            'Precision': self.meta_results['precision'],
            'Recall': self.meta_results['recall'],
            'F1_Score': self.meta_results['f1'],
            'AUC': self.meta_results['auc']
        })
        
        # ä¿å­˜æŠ¥å‘Š
        report_df = pd.DataFrame(report_data)
        report_df.to_csv("output/csv/ç¬¬äºŒé—®/model_performance_report.csv", 
                        index=False, encoding='utf-8-sig')
        
    def _save_feature_importance(self):
        """ä¿å­˜ç‰¹å¾é‡è¦æ€§"""
        for disease, importance in self.feature_importance.items():
            importance_df = pd.DataFrame([
                {'Feature': feature, 'Importance': imp}
                for feature, imp in importance.items()
            ]).sort_values('Importance', ascending=False)
            
            importance_df.to_csv(f"output/csv/ç¬¬äºŒé—®/{disease}_feature_importance.csv", 
                               index=False, encoding='utf-8-sig')
        
    def _generate_visualizations(self):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        # 1. æ¨¡å‹æ€§èƒ½å¯¹æ¯”
        self._plot_model_comparison()
        
        # 2. ç‰¹å¾é‡è¦æ€§
        self._plot_feature_importance()
        
        # 3. ROCæ›²çº¿
        self._plot_roc_curves()
        
        # 4. çµæ•åº¦åˆ†æç»“æœ
        self._plot_sensitivity_analysis()
        
    def _plot_model_comparison(self):
        """ç»˜åˆ¶æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        metrics = ['Accuracy', 'Precision', 'Recall', 'AUC']
        
        for i, metric in enumerate(metrics):
            ax = axes[i//2, i%2]
            
            data = []
            for disease in ['stroke', 'heart', 'cirrhosis']:
                results = self.specialists[disease]['results']
                for model_name, result in results.items():
                    data.append({
                        'Disease': disease,
                        'Model': model_name,
                        metric: result[metric.lower().replace('auc', 'auc')]
                    })
            
            df = pd.DataFrame(data)
            sns.barplot(data=df, x='Disease', y=metric, hue='Model', ax=ax)
            ax.set_title(f'{metric} Comparison')
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        plt.tight_layout()
        plt.savefig("output/plt/ç¬¬äºŒé—®/model_comparison.png", dpi=300, bbox_inches='tight')
        plt.close()
        
    def _plot_feature_importance(self):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾"""
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        
        for i, disease in enumerate(['stroke', 'heart', 'cirrhosis']):
            if disease in self.feature_importance:
                importance = self.feature_importance[disease]
                features = list(importance.keys())[:10]  # å‰10ä¸ªç‰¹å¾
                values = [importance[f] for f in features]
                
                axes[i].barh(features, values)
                axes[i].set_title(f'{disease.capitalize()} Feature Importance')
                axes[i].set_xlabel('Importance')
        
        plt.tight_layout()
        plt.savefig("output/plt/ç¬¬äºŒé—®/feature_importance.png", dpi=300, bbox_inches='tight')
        plt.close()
        
    def _plot_roc_curves(self):
        """ç»˜åˆ¶ROCæ›²çº¿"""
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        
        for i, disease in enumerate(['stroke', 'heart', 'cirrhosis']):
            results = self.specialists[disease]['results']
            y_test = self.specialists[disease]['y_test']
            
            for model_name, result in results.items():
                fpr, tpr, _ = roc_curve(y_test, result['y_pred_proba'])
                auc = result['auc']
                
                axes[i].plot(fpr, tpr, label=f'{model_name} (AUC={auc:.3f})')
            
            axes[i].plot([0, 1], [0, 1], 'k--', alpha=0.5)
            axes[i].set_xlabel('False Positive Rate')
            axes[i].set_ylabel('True Positive Rate')
            axes[i].set_title(f'{disease.capitalize()} ROC Curves')
            axes[i].legend()
            axes[i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig("output/plt/ç¬¬äºŒé—®/roc_curves.png", dpi=300, bbox_inches='tight')
        plt.close()
        
    def _plot_sensitivity_analysis(self):
        """ç»˜åˆ¶çµæ•åº¦åˆ†æç»“æœ"""
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        
        for i, disease in enumerate(['stroke', 'heart', 'cirrhosis']):
            sensitivity = self.sensitivity_results[disease]['feature_sensitivity']
            
            if sensitivity:
                features = list(sensitivity.keys())
                perturbations = [-0.2, -0.1, 0, 0.1, 0.2]
                
                for feature in features[:5]:  # å‰5ä¸ªç‰¹å¾
                    changes = [sensitivity[feature][p] for p in perturbations]
                    axes[i].plot(perturbations, changes, marker='o', label=feature)
                
                axes[i].set_xlabel('Perturbation (%)')
                axes[i].set_ylabel('Probability Change Rate')
                axes[i].set_title(f'{disease.capitalize()} Feature Sensitivity')
                axes[i].legend()
                axes[i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig("output/plt/ç¬¬äºŒé—®/sensitivity_analysis.png", dpi=300, bbox_inches='tight')
        plt.close()
        
    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹ - æè‡´GPUåŠ é€Ÿç‰ˆæœ¬"""
        print("ğŸš€ å¼€å§‹æè‡´GPUåŠ é€Ÿç–¾ç—…é¢„æµ‹æ¨¡å‹æ„å»º...")
        total_start_time = time.time()
        
        # 1. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
        self.load_and_preprocess_data()
        
        # 2. è®­ç»ƒä¸“ç§‘åŒ»ç”Ÿæ¨¡å‹
        self.train_specialists()
        
        # 3. åˆ›å»ºå…ƒç‰¹å¾
        self.create_meta_features()
        
        # 4. è®­ç»ƒå…ƒæ¨¡å‹
        self.train_meta_model()
        
        # 5. çµæ•åº¦åˆ†æ
        self.sensitivity_analysis()
        
        # 6. ç”ŸæˆæŠ¥å‘Š
        self.generate_reports()
        
        # 7. ä¿å­˜æ¨¡å‹
        self.save_models()
        
        total_elapsed_time = time.time() - total_start_time
        print(f"ğŸ‰ æè‡´GPUåŠ é€Ÿç–¾ç—…é¢„æµ‹æ¨¡å‹æ„å»ºå®Œæˆï¼")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_elapsed_time:.2f}ç§’")
        print("ğŸ“ ç»“æœä¿å­˜åœ¨ output/csv/ç¬¬äºŒé—® å’Œ output/plt/ç¬¬äºŒé—® æ–‡ä»¶å¤¹ä¸­")
        print("ğŸ’¾ æ¨¡å‹ä¿å­˜åœ¨ models/ æ–‡ä»¶å¤¹ä¸­")

if __name__ == "__main__":
    # åˆ›å»ºé¢„æµ‹å™¨å¹¶è¿è¡Œåˆ†æ
    predictor = DiseasePredictor()
    predictor.run_complete_analysis() 